# CS224N Course Resources

## Course Materials by Topic

### Week 1: Word Vectors
- **Papers**:
  - [Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/pdf/1301.3781.pdf) (Original word2vec paper)
  - [Distributed Representations of Words and Phrases and their Compositionality](https://proceedings.neurips.cc/paper_files/paper/2013/file/9aa42b31882ec039965f3c4923ce901b-Paper.pdf) (Negative sampling paper)
  - [GloVe: Global Vectors for Word Representation](https://nlp.stanford.edu/pubs/glove.pdf)
  - [Improving Distributional Similarity with Lessons Learned from Word Embeddings](https://aclanthology.org/Q15-1016.pdf)
  - [Evaluation methods for unsupervised word embeddings](https://aclanthology.org/D15-1036.pdf)

### Week 2: Neural Networks & Dependency Parsing
- **Neural Network Resources**:
  - [Matrix Calculus Notes](http://cs231n.stanford.edu/vecDerivs.pdf)
  - [CS231n Neural Network Notes](http://cs231n.github.io/neural-networks-1/)
  - [Backpropagation Notes](http://cs231n.github.io/optimization-2/)
  - [Learning Representations by Backpropagating Errors](https://www.nature.com/articles/323533a0) (Rumelhart et al.)

- **Dependency Parsing**:
  - [Incrementality in Deterministic Dependency Parsing](https://aclanthology.org/W04-0308.pdf)
  - [A Fast and Accurate Dependency Parser using Neural Networks](https://aclanthology.org/D14-1082.pdf)
  - [Universal Stanford Dependencies](https://nlp.stanford.edu/pubs/USD_LREC14_paper_camera_ready.pdf)
  - [Universal Dependencies Website](https://universaldependencies.org/)

### Week 3: RNNs & Sequence Models
- **RNN Resources**:
  - [The Unreasonable Effectiveness of RNNs](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)
  - [Understanding LSTM Networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)
  - [On the difficulty of training RNNs](http://proceedings.mlr.press/v28/pascanu13.pdf)

### Week 4-5: Transformers & Pretraining
- **Transformer Architecture**:
  - [Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf)
  - [The Illustrated Transformer](http://jalammar.github.io/illustrated-transformer/)
  - [BERT Paper](https://arxiv.org/pdf/1810.04805.pdf)
  - [The Illustrated BERT](http://jalammar.github.io/illustrated-bert/)

### Week 6-10: Advanced Topics
- **Efficient Training**:
  - [Mixed Precision Training](https://arxiv.org/pdf/1710.03740.pdf)
  - [ZeRO: Memory Optimizations](https://arxiv.org/pdf/1910.02054.pdf)
  - [LoRA Paper](https://arxiv.org/pdf/2106.09685.pdf)

- **Reasoning & Agents**:
  - [ReAct Paper](https://arxiv.org/pdf/2210.03629.pdf)
  - [WebArena Paper](https://arxiv.org/pdf/2307.13854.pdf)